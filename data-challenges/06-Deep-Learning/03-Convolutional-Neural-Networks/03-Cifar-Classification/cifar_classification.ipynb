{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR10 Classification Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eEt4AJqKVj0v"
   },
   "source": [
    "üéØ **Exercise objectives**\n",
    "\n",
    "1. Implement a CNN to solve a **`10-class classification problem`**\n",
    "2. Enhance the CNN's performance with **`Data Augmentation Techniques`**\n",
    "3. Experiment with **`GPUs to Accelerate Image Processing using Google Colab`**\n",
    "\n",
    "<hr>\n",
    "\n",
    "\n",
    "üëè You should now have a better feeling of:\n",
    "* how CNNs works, \n",
    "* and especially how convolutions scan images to detect specific features. \n",
    "\n",
    "üöÄ It's time to play with images that are a bit more complex than the handwritten digits or the triangles/circles. \n",
    "\n",
    "üé® From [Wikipedia](https://en.wikipedia.org/wiki/CIFAR-10) (*click on the link for further information*):\n",
    "\n",
    "> The **`CIFAR-10`** dataset (Canadian Institute For Advanced Research) is a collection of images that are commonly used to train machine learning and computer vision algorithms. It is one of the most widely used datasets for machine learning research. The CIFAR-10 dataset contains 60,000 32x32 color images in 10 different classes. The 10 different classes represent airplanes, cars, birds, cats, deer, dogs, frogs, horses, ships, and trucks. There are 6,000 images of each class.\n",
    "\n",
    "<img src=\"https://people.minesparis.psl.eu/fabien.moutarde/ES_MachineLearning/mini-projets/cifar10_notebook_fichiers/cifar_10.png\">\n",
    "\n",
    "‚≠êÔ∏è This dataset is iconic in the research community as many enhancements for image recognition have been achieved on this dataset. After achieving great performance on this dataset, researchers moved to the more advanced CIFAR-100.\n",
    "\n",
    "From the [University of Toronto](https://www.cs.toronto.edu/~kriz/cifar.html):\n",
    "\n",
    "> This dataset is just like the CIFAR-10, except it has 100 classes containing 600 images each. There are 500 training images and 100 testing images per class. The 100 classes in the CIFAR-100 are grouped into 20 superclasses. Each image comes with a \"fine\" label (the class to which it belongs) and a \"coarse\" label (the superclass to which it belongs).\n",
    "Here is the list of classes in the CIFAR-100:\n",
    "\n",
    "\n",
    "üî• In this notebook, let's implement a CNN to distinguish the 10 categories from the CIFAR-10 dataset.\n",
    "\n",
    "‚ùóÔ∏è Again, remember that until 10 years ago, this problem was very challenging for the entire research community. As you have been sharpening your CNN skills, it's time to shine!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (0) Colab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OE3R20SasW6i"
   },
   "source": [
    "You are strongly advised to use **`Google Colab`** for this challenge and the rest of this Deep Learning Module.\n",
    "\n",
    "* Read this <a href=\"https://kitt.lewagon.com/knowledge/tutorials/data_google_colab\">tutorial on Kitt</a>\n",
    "\n",
    "*  **If you follow our advice to use Colab, make sure to use the GPU acceleration** by clicking on:\n",
    "    * `Runtime` $\\rightarrow$ `Change runtime` $\\rightarrow$ `GPU`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZY44N5e6T2Il"
   },
   "source": [
    "## (1) Loading the CIFAR10 Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question: Loading the CIFAR10 Dataset** ‚ùì\n",
    "\n",
    "\n",
    "* üéÅ We took care of the `data loading and preprocessing` for you. \n",
    "* ‚ñ∂Ô∏è Just run the following cell and make sure you understand the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16493,
     "status": "ok",
     "timestamp": 1619681093737,
     "user": {
      "displayName": "Bruno Lajoie",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg0dl6gThG8gOPbCvHbgt62zQnsi8cgbQ7C5HkD_Cg=s64",
      "userId": "15793030209206844069"
     },
     "user_tz": -120
    },
    "id": "ZkKdhZXWVj00",
    "outputId": "6d5cf9e1-b3b9-4728-cbd3-618990fb680e"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import cifar10\n",
    "import numpy as np\n",
    "\n",
    "(images_train, labels_train), (images_test, labels_test) = cifar10.load_data()\n",
    "\n",
    "labels = ['airplane', \n",
    "          'automobile',\n",
    "          'bird',\n",
    "          'cat',\n",
    "          'deer',\n",
    "          'dog',\n",
    "          'frog',\n",
    "          'horse',\n",
    "          'ship',\n",
    "          'truck']\n",
    "\n",
    "print(images_train.shape, images_test.shape)\n",
    "unique, counts = np.unique(labels_train, return_counts=True)\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1.1) Working on a smaller dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZI_3K-MHT2In"
   },
   "source": [
    "‚ùì **Question about the training size** ‚ùì\n",
    "\n",
    "* $50 000$ images may take a long time to train...\n",
    "* üë®üèª‚Äçüè´ **Always start with a subsample to iterate quickly** before scaling up üè´\n",
    "* Run the next cell where we are reducing the dataset size by `reduction_factor = 10`. Don't try to increase it unless we ask you to do so..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1023,
     "status": "ok",
     "timestamp": 1619681314218,
     "user": {
      "displayName": "Bruno Lajoie",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg0dl6gThG8gOPbCvHbgt62zQnsi8cgbQ7C5HkD_Cg=s64",
      "userId": "15793030209206844069"
     },
     "user_tz": -120
    },
    "id": "wR_JXHmlT2Io",
    "outputId": "1732fcfc-3227-43e9-b2bd-f1257ea48755"
   },
   "outputs": [],
   "source": [
    "# Considering only 1/10th of the 50_000 images\n",
    "reduction_factor = 10\n",
    "\n",
    "# Choosing the random indices of small train set and small test set\n",
    "idx_train =  np.random.choice(len(images_train), round(len(images_train)/reduction_factor))\n",
    "idx_test =  np.random.choice(len(images_test), round(len(images_test)/reduction_factor))\n",
    "\n",
    "# Collecting the two subsamples images_train_small and images_test_small from images_train and images_test\n",
    "images_train_small = images_train[idx_train]\n",
    "images_test_small = images_test[idx_test]\n",
    "# and their corresponding labels\n",
    "labels_train_small = labels_train[idx_train]\n",
    "labels_test_small = labels_test[idx_test]\n",
    "\n",
    "print(\"------------------ Before -----------------\")\n",
    "print(images_train.shape, images_test.shape)\n",
    "\n",
    "print(\"\")\n",
    "\n",
    "print(\"--- After applying the reduction factor ---\")\n",
    "print(images_train_small.shape, images_test_small.shape)\n",
    "\n",
    "print(\"\")\n",
    "print(\"-\"*43)\n",
    "\n",
    "unique, counts = np.unique(labels_train_small, return_counts=True)\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëá You are working with images.. so it would be a good idea to look at some of them :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 183
    },
    "executionInfo": {
     "elapsed": 2061,
     "status": "ok",
     "timestamp": 1619681318700,
     "user": {
      "displayName": "Bruno Lajoie",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg0dl6gThG8gOPbCvHbgt62zQnsi8cgbQ7C5HkD_Cg=s64",
      "userId": "15793030209206844069"
     },
     "user_tz": -120
    },
    "id": "hQ62jK5VVj03",
    "outputId": "5dfa91d5-48ad-4fae-8e9f-a09b13b0b611"
   },
   "outputs": [],
   "source": [
    "# Let's plot few images to see what they look like\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "for i in range(6):\n",
    "    plt.subplot(1,6, i+1)\n",
    "    img = images_train[i]\n",
    "    label = labels_train[i][0]\n",
    "    plt.imshow(img)\n",
    "    plt.title(labels[label])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1.2) Image preprocesing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WMG4ttoHVj02"
   },
   "source": [
    "üëâ As usual, let's:\n",
    "- normalize the pixels' intensities between 0 and 1\n",
    "- turn the `labels_train` and `labels_test` into \"one-hot-encoded\" targets that we will call respectively `y_train` and `y_cat`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2009,
     "status": "ok",
     "timestamp": 1619681319177,
     "user": {
      "displayName": "Bruno Lajoie",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg0dl6gThG8gOPbCvHbgt62zQnsi8cgbQ7C5HkD_Cg=s64",
      "userId": "15793030209206844069"
     },
     "user_tz": -120
    },
    "id": "Fm8XRTbiVj02"
   },
   "outputs": [],
   "source": [
    "### Normalizing pixels' intensities\n",
    "\n",
    "X_train = images_train / 255.\n",
    "X_train_small = images_train_small / 255.\n",
    "X_test = images_test / 255.\n",
    "X_test_small = images_test_small / 255.\n",
    "\n",
    "### Encoding the labels\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "y_train = to_categorical(labels_train, 10)\n",
    "y_train_small = to_categorical(labels_train_small, 10)\n",
    "y_test = to_categorical(labels_test, 10)\n",
    "y_test_small = to_categorical(labels_test_small, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) Iterate on your CNN architecture using your small training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ke9YJk7MVj04"
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "‚ùì **Question** ‚ùì Time to shine ‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è !\n",
    "\n",
    "1. Define the CNN architecture of your choice in an `initialize_model()` function:\n",
    "2. Compile your model in a `compile_model()` method:\n",
    "3. Fit your CNN only on the `small training set` and save the training information in an `history` variable\n",
    "---\n",
    "* Feeling lost?\n",
    "* Do you want to improve your performance ? \n",
    "\n",
    "<details>\n",
    "    <summary>üÜò PRO TIPS üÜò</summary>\n",
    "\n",
    "\n",
    "- Do not forget to add the **`input shape`** of your images to the first layer: it has 3 colors\n",
    "- **`Start simple, add complexity later `** after several attempts to get better results\n",
    "- The task is complex: **`Try at least 3 or 4 convolutions`**, you want your **images to go through different magnifying glasses / kernels from different convolutional layers!**\n",
    "- The Kernel Size does not need to be large for such a small picture resolution!\n",
    "- Add some **`MaxPooling2D`** (but not too much, otherwise the activation \"image\" will become too small)\n",
    "- Keep `padding = \"same\"` and `stride = (1,1)` to start with.\n",
    "- Once your model overfits, try to add some **`Dropout Layers` to regularize the network**. A good tip is to **increase the Dropout Rate/Strength as you move closer to the prediction layer** to prevent your CNN from overfitting\n",
    "- Images are so small in CIFAR10, you can afford to use a larger batch size (32 or 64) to benefit even more from **GPU parallelization**!\n",
    "</details>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1498,
     "status": "ok",
     "timestamp": 1619681319178,
     "user": {
      "displayName": "Bruno Lajoie",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg0dl6gThG8gOPbCvHbgt62zQnsi8cgbQ7C5HkD_Cg=s64",
      "userId": "15793030209206844069"
     },
     "user_tz": -120
    },
    "id": "GNOtE5xhVj04"
   },
   "outputs": [],
   "source": [
    "def initialize_model():\n",
    "    '''instanciate and return the CNN architecture of your choice with less than 150,000 params'''\n",
    "    # YOUR CODE HERE\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1062,
     "status": "ok",
     "timestamp": 1619681319179,
     "user": {
      "displayName": "Bruno Lajoie",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg0dl6gThG8gOPbCvHbgt62zQnsi8cgbQ7C5HkD_Cg=s64",
      "userId": "15793030209206844069"
     },
     "user_tz": -120
    },
    "id": "7C9AL4uBT2Iq"
   },
   "outputs": [],
   "source": [
    "def compile_model(model):\n",
    "    '''return a compiled model suited for the CIFAR-10 task'''\n",
    "    # YOUR CODE HERE\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YcPQtVjdVj06"
   },
   "source": [
    "‚ùì **Question: History of your training** ‚ùì \n",
    "\n",
    "Run the following function on the previous history \n",
    "_(keep the default arguments, these are intended for future plots in the notebook)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 830,
     "status": "ok",
     "timestamp": 1619681397197,
     "user": {
      "displayName": "Bruno Lajoie",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg0dl6gThG8gOPbCvHbgt62zQnsi8cgbQ7C5HkD_Cg=s64",
      "userId": "15793030209206844069"
     },
     "user_tz": -120
    },
    "id": "lIR_L7UfVj06"
   },
   "outputs": [],
   "source": [
    "def plot_history(history, title='', axs=None, exp_name=\"\"):\n",
    "    if axs is not None:\n",
    "        ax1, ax2 = axs\n",
    "    else:\n",
    "        f, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    \n",
    "    if len(exp_name) > 0 and exp_name[0] != '_':\n",
    "        exp_name = '_' + exp_name\n",
    "    ax1.plot(history.history['loss'], label = 'train' + exp_name)\n",
    "    ax1.plot(history.history['val_loss'], label = 'val' + exp_name)\n",
    "    ax1.set_ylim(0., 2.2)\n",
    "    ax1.set_title('loss')\n",
    "    ax1.legend()\n",
    "\n",
    "    ax2.plot(history.history['accuracy'], label='train accuracy'  + exp_name)\n",
    "    ax2.plot(history.history['val_accuracy'], label='val accuracy'  + exp_name)\n",
    "    ax2.set_ylim(0.25, 1.)\n",
    "    ax2.set_title('Accuracy')\n",
    "    ax2.legend()\n",
    "    return (ax1, ax2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "executionInfo": {
     "elapsed": 1798,
     "status": "ok",
     "timestamp": 1619681398327,
     "user": {
      "displayName": "Bruno Lajoie",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg0dl6gThG8gOPbCvHbgt62zQnsi8cgbQ7C5HkD_Cg=s64",
      "userId": "15793030209206844069"
     },
     "user_tz": -120
    },
    "id": "bDxbLDt2Vj07",
    "outputId": "7ab421fd-4c7f-4886-bd12-2d1814bd83fa",
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OR7l9LxMVj07"
   },
   "source": [
    "‚ùì **Question: Evaluating your CNN** ‚ùì \n",
    "\n",
    "* Evaluate your model on the test data and compare it with a baseline accuracy. \n",
    "* Are you satisfied with this performance?\n",
    "* Look at the `PRO TIPS` above and iterate a bit if you want to improve your performance!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1010,
     "status": "ok",
     "timestamp": 1619681399234,
     "user": {
      "displayName": "Bruno Lajoie",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg0dl6gThG8gOPbCvHbgt62zQnsi8cgbQ7C5HkD_Cg=s64",
      "userId": "15793030209206844069"
     },
     "user_tz": -120
    },
    "id": "WwnwvmV5Vj08",
    "outputId": "f5e17e5f-41ff-48fb-e961-b0c53c118d66",
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z7P9y-LwVjdx"
   },
   "source": [
    "## (3) Increase the size of your training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UMHH_qsbVT_0"
   },
   "source": [
    "‚ùì **Question: train your model on the full dataset** ‚ùì \n",
    "\n",
    "- Switch to **Colab** if you haven't done it before\n",
    "- Make sure to use the **GPU acceleration** by clicking on `Runtime` $\\rightarrow$ `Change runtime` $\\rightarrow$ `GPU`\n",
    "\n",
    "üí° Training neural networks on images (in each batch) can be parallelized, and this **`parallelization procedure`** can be done on **`GPU`**.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pWHicYsosW6o",
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should witness significant performance improvement\n",
    "\n",
    "Welcome to the Deep Learning paradigm, where big data makes a significant difference.\n",
    "\n",
    "But what happens if I can access only a limited amount of pictures? Think about biologists studying rare species. What can they do?\n",
    "* To improve the accuracy of a model without much work, we can **generate new data**. \n",
    "* The process is called... ‚≠êÔ∏è **`Data Augmentation`** ‚≠êÔ∏è ! \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (4) Data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* üë©üèª‚Äçüè´ <b><u>Data Augmentation</u></b>\n",
    "    * This technique is widely-used and consists of applying little transformations to the input images without changing their labels: ***mirroring***, ***cropping***, ***intensity changes***, etc... \n",
    "    * The _improved performance_ simply results from the CNN training with more images (the original pictures + the \"augmented\" ones).\n",
    "    \n",
    "\n",
    "* üëâ <b><u>Theoretically:</u></b>\n",
    "    * (1) We could generate these new images by applying some transformations on copies of the original pictures\n",
    "    * (2) Train the model on the original images + new images. \n",
    "    \n",
    "    \n",
    "* üö®  <b><u>Problem:</u></b>\n",
    "    * Such a procedure requires storing all these images in memory...\n",
    "    * It can be very intensive, so much so that your computer's RAM cannot hold them all\n",
    "    \n",
    "    \n",
    "* ü¶Ñ <b><u>In Practice:</u></b>\n",
    "    * When a Neural Network operates a forward/backward propagation, it only requires to see 16 pictures at a time if you chose $ batch size = 16 $ for example. It doesn't need to store all the original images or the augmented images in the RAM.\n",
    "    * For this reason, we will **augment the data on the fly (batch per batch)**. What does that mean? For every epoch and every batch, during the ***.fit()*** training procedure, we will:\n",
    "        1. Generate some `augmented data/images`\n",
    "        2. Fit the model on the images and their augmented versions\n",
    "        3. Delete the images and their augmented versions from the RAM\n",
    "        4. Repeat steps 1-2-3\n",
    "        \n",
    "* üìö <a href= \"https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator\"><b><u>tf/keras/preprocessing/image/ImageDataGenerator:</u></b></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wk8ZZVunVj08"
   },
   "source": [
    "‚ùì **Question: using an ImageDataGenerator** ‚ùì\n",
    "\n",
    "Look at the following code down below üëá\n",
    "* The general syntax may look strange but don't worry: \n",
    "    * First, focus on the arguments of the *ImageDataGenerator* which define the augmentation techniques that we are using\n",
    "    * and then check the <a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator\">**`ImageDataGenerator`**</a> documentation later\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 163449,
     "status": "ok",
     "timestamp": 1619623286033,
     "user": {
      "displayName": "Bruno Lajoie",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg0dl6gThG8gOPbCvHbgt62zQnsi8cgbQ7C5HkD_Cg=s64",
      "userId": "15793030209206844069"
     },
     "user_tz": -120
    },
    "id": "DlOpbos5Vj09",
    "outputId": "b21acfa3-8d9f-42cb-c130-f4c193e88231"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center = False,\n",
    "    featurewise_std_normalization = False,\n",
    "    rotation_range = 10,\n",
    "    width_shift_range = 0.1,\n",
    "    height_shift_range = 0.1,\n",
    "    horizontal_flip = True,\n",
    "    zoom_range = (0.8, 1.2),\n",
    "    ) \n",
    "\n",
    "datagen.fit(X_train)\n",
    "datagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 163749,
     "status": "ok",
     "timestamp": 1619623286340,
     "user": {
      "displayName": "Bruno Lajoie",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg0dl6gThG8gOPbCvHbgt62zQnsi8cgbQ7C5HkD_Cg=s64",
      "userId": "15793030209206844069"
     },
     "user_tz": -120
    },
    "id": "Zcl17dW1aA0G",
    "outputId": "370101ad-cb62-4f51-bd8d-568191d57556"
   },
   "outputs": [],
   "source": [
    "X_augmented_iterator = datagen.flow(X_train, shuffle=False, batch_size=1)\n",
    "X_augmented_iterator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RdMqg8grVj09"
   },
   "source": [
    "‚ùóÔ∏è Always **visualize the augmented images** in order to double-check whether you can still recognize the labels yourself or not ‚ùóÔ∏è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 166091,
     "status": "ok",
     "timestamp": 1619623288689,
     "user": {
      "displayName": "Bruno Lajoie",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg0dl6gThG8gOPbCvHbgt62zQnsi8cgbQ7C5HkD_Cg=s64",
      "userId": "15793030209206844069"
     },
     "user_tz": -120
    },
    "id": "IsqMF0adVj09",
    "outputId": "5bb32536-a174-423a-fc4e-fc0e82bc4d68"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "for i, (raw_image, augmented_image) in enumerate(zip(X_train, X_augmented_iterator)):\n",
    "    _, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 2))\n",
    "    ax1.imshow(raw_image)\n",
    "    ax2.imshow(augmented_image[0])\n",
    "    plt.show()\n",
    "    \n",
    "    if i > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LyLlJQrKVj09"
   },
   "source": [
    "‚ùó **Remarks** ‚ùó \n",
    "\n",
    "* Each image from **`X_augmented_iterator`** is an ***augmented image*** of one image located in the original `X_train` image dataset\n",
    "* This augmentation process is done once per epoch.\n",
    "* During one epoch, the model will:\n",
    "    1. *create the augmented version* of each picture from `X_train`, \n",
    "    2. for each image of `X_train`, *the model will randomly pick either the original version in `X_train` or its augmented version in `X_augmented_iterator`*\n",
    "    3. and the model will be *fitted on the combination of some original images + some augmented images*\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question: what is the validation set when we have augmented images** ‚ùì \n",
    "\n",
    "* Previously, we used the `validation_split` argument to let the model separate the training set into a Train/Validation split when fitting the model for each epoch.\n",
    "* It is not possible to use this kind of Train/Val Split here as **using an image in the training set and its transformation in the validation set is considered `data leakage`** !. \n",
    "* Therefore, we have to define the **`validation_data`** manually with the following commands: take time to understand the cell down below:üëá \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lYOkY7LOVj09"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# The model\n",
    "model_aug = initialize_model()\n",
    "model_aug = compile_model(model_aug)\n",
    "\n",
    "# The data generator\n",
    "X_tr = X_train[:40000]\n",
    "y_tr = y_train[:40000]\n",
    "X_val = X_train[40000:]\n",
    "y_val = y_train[40000:]\n",
    "train_flow = datagen.flow(X_tr, y_tr, batch_size = 64)\n",
    "\n",
    "# The early stopping criterion\n",
    "es = EarlyStopping(patience = 3)\n",
    "\n",
    "# The fit\n",
    "history_aug = model_aug.fit(train_flow, \n",
    "                        epochs = 50, \n",
    "                        callbacks = [es], \n",
    "                        validation_data = (X_val, y_val))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NmQ9t_cMVj0-"
   },
   "source": [
    "üö® The training can be quite long here...\n",
    "\n",
    "üëâ Feel free to move on to the next exercise and come back to this notebook later to finish the last questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question: How did the model with an augmented dataset perform?** ‚ùì \n",
    "\n",
    "Let's plot the previous and current run histories. What do you think of the data augmentation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 515585,
     "status": "ok",
     "timestamp": 1619623638195,
     "user": {
      "displayName": "Bruno Lajoie",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg0dl6gThG8gOPbCvHbgt62zQnsi8cgbQ7C5HkD_Cg=s64",
      "userId": "15793030209206844069"
     },
     "user_tz": -120
    },
    "id": "o9r4Fau2Vj0-",
    "outputId": "bd72c691-c91e-49d8-9ad3-74e63763bacb",
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jm055RyNVj0-"
   },
   "source": [
    "ü•° <b><u>Some takeaways from Data Augmentation:</u></b>\n",
    "\n",
    "* Data augmentation may not improve your performance easily...\n",
    "\n",
    "* Here it even decreased the performance!\n",
    "\n",
    "* Its impact strongly depends on \n",
    "    * the model architecture you used\n",
    "    * the learning rate, \n",
    "    * the type of augmentation chosen, etc...\n",
    "\n",
    "* Image classification is an art that requires months and years of practice to master!\n",
    "\n",
    "üö® **Don't spend too much time trying to finetune your model for the moment!  You have 3 other interesting challenges to investigate!**. üö®\n",
    "\n",
    "üìö [Here is a good example of a solution for future reference](https://machinelearningmastery.com/how-to-develop-a-cnn-from-scratch-for-cifar-10-photo-classification/).<br>\n",
    "They managed to reach an accuracy level of approx. 80%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oy4DCYLGVj0-"
   },
   "source": [
    "---\n",
    "\n",
    "üèÅ **Congratulations** üèÅ \n",
    "\n",
    "1. Download this notebook from your `Google Drive` or directly from `Google Colab` \n",
    "2. Drag-and-drop it from your `Downloads` folder to your local `[GITHUB_USERNAME]/data-challenges/06-Deep-Learning/03-Convolutional-Neural-Networks/03-Cifar-Classification`\n",
    "\n",
    "\n",
    "üíæ Don't forget to push your code\n",
    "\n",
    "3. Follow the usual procedure on your terminal in the `06-Deep-Learning/03-Convolutional-Neural-Networks/03-Cifar-Classification` folder:\n",
    "      * *git add cifar_classification.ipynb*\n",
    "      * *git commit -m \"I am the god of CNNs\"*\n",
    "      * *git push origin master*\n",
    "\n",
    "*Hint*: To find where this Colab notebook has been saved, click on `File` $\\rightarrow$ `Locate in Drive`.\n",
    "\n",
    "üöÄ It is time to move on to the **Transfer Learning** challenge!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
