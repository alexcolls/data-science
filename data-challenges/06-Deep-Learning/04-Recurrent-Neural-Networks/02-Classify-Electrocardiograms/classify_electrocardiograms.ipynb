{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify Electrocardiograms (ECG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "source": [
    "<img src='https://upload.wikimedia.org/wikipedia/commons/9/9e/SinusRhythmLabels.svg' width=400>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "source": [
    "🧑🏻‍🏫 We saw in the first challenge that **Recurrent Neural Networks are well designed to work with sequence prediction problems**: based on an observed sequence of data, RNNs are used to predict what will happen next (predicting the next value(s) of a temperature, a stock price, ... $ \\rightarrow $ ***regression task***).\n",
    "\n",
    "👉 Let's see a different way to use RNNs. Instead of predicting a value that occurs after the observed sequence, we will ***classify the entire sequence*** itself, as if the whole sequence corresponds to a given category. \n",
    "\n",
    "🎯 Exercise objectives:\n",
    "- Discover a new type of application with temporal data: classification\n",
    "- Try different RNN architectures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) The ECG dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "source": [
    "* The data corresponds to electrocardiograms (ECG), which are basically heartbeats.\n",
    "    - Each sequence is therefore a sequence of amplitudes. \n",
    "    - These ECGs are often used to observe heart malfunctions! \n",
    "* In this dataset, there are 87554 heartbeats and each of them corresponds to a heartbeat type, ranging from 0 to 4:\n",
    "    - 0 : Normal beat\n",
    "    - 1 : Supraventricular\n",
    "    - 2 : Ventricular\n",
    "    - 3 : Fusion\n",
    "    - 4 : Beats that cannot be classified"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1.1) Loading the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "source": [
    "<u><b>Instructions:</b></u>\n",
    "* Run the following command to download the data from [here](https://storage.googleapis.com/data-sciences-bootcamp/ECG_data.zip)\n",
    "* Unzip them\n",
    "* Read it as python object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! wget \"http://storage.googleapis.com/data-sciences-bootcamp/ECG_data.zip\"\n",
    "! unzip ECG_data.zip\n",
    "! rm ECG_data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.load('ECG_data/X.npy', allow_pickle=True).tolist()\n",
    "y = np.load('ECG_data/y.npy', allow_pickle=True).tolist()\n",
    "\n",
    "print(len(X), \"time series\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1.2) Visualizing some ECGs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🎁 We gave you a piece of Python code to plot one ECG for each category in the dataset \n",
    "\n",
    "👩🏻‍⚕️ *Run the following cell* to see what an ECG looks like for each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.cm import get_cmap\n",
    "\n",
    "# ------------------------- #\n",
    "#      Some colormaps       #\n",
    "# ------------------------- #\n",
    "\n",
    "name = \"tab20c\"\n",
    "cmap = get_cmap(name)  # type: matplotlib.colors.ListedColormap\n",
    "colors_list = cmap.colors\n",
    "\n",
    "\n",
    "# ------------------------- #\n",
    "#      Some ECG             #\n",
    "# ------------------------- #\n",
    "\n",
    "fix, axs = plt.subplots(5,5, figsize=(15,10))\n",
    "\n",
    "for i in range(5): # Five examples per category\n",
    "    for j in range(5): # Iterating over the 5 categories\n",
    "        idx_C = np.argwhere(np.array(y) == j)  # Collecting the indexes of all the heartbeats of category j\n",
    "        axs[i,j].plot(X[idx_C[i][0]], label=f'Category {j}', c=colors_list[j+3]) # Plotting the ECG\n",
    "        # Some cosmetic tricks down below\n",
    "        if i == 0:\n",
    "            axs[i,j].legend(loc='upper center')\n",
    "            if j ==0:\n",
    "                axs[i,j].set_xlabel('Time')\n",
    "                axs[i,j].set_ylabel('ECG Amplitude')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1.3) Padding the sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🕵🏻‍♂️ You have (probably?) notice that each sequence, i.e. each ECG, has a different length."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Question** ❓ Plot the distribution of the sequences' lengths in the dataset to confirm this observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🧑🏻‍🏫 Remember that Neural Networks are fed with tensors, batch per batch. The shape of these tensors is the following:\n",
    "\n",
    "\n",
    ">`(# SEQUENCES, # OBSERVATIONS per sequence, # FEATURES per observation)`\n",
    "\n",
    "- `# SEQUENCES` = $87554$ sequences\n",
    "- `# OBSERVATIONS per sequence` = ❗️***the number of observations varies from one sequence to another one***❗️ \n",
    "- `# FEATURES per observation` = each observation collects only $1$ feature = the amplitude of the ECG.\n",
    "\n",
    "😰 Such a tensor is called a ***ragged tensor***. For computational reasons, this cannot be fed into a Recurrent Neural Network. \n",
    "\n",
    "💡 RNNs need to be fed with proper tensors. For this reason, you need to \"***fill in the blanks of each sequence***\". Using [**`pad_sequences`**](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/sequence/pad_sequences), each sequence will be filled with fake values. The resulting sequences will all be the same length.\n",
    "\n",
    "<img src=\"https://github.com/lewagon/data-images/blob/master/DL/tensors_in_rnn.png?raw=true\" alt=\"Tensors in RNN\" width=\"500\" height=\"600\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Question** ❓ Apply the [`pad_sequences`](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/sequence/pad_sequences) function directly on X *without any extra arguments here*, store the result in `X_pad` and print the first sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🤔 Surprising, right? You are probably observing that the returned sequence is composed only of _zeros_. The reason is that, by default, `pad_sequences` returns integers. If a float is between 0.0 and 0.99999..., it will be converted to 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Question** ❓  To change this default behavior, set the `dtype` argument of `pad_sequences` to `float32`. Pad the sequences once again, store the new result in `X_pad` and print the first sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "👨🏻‍🏫 How will the Recurrent Neural Network know that a zero is a fake value used as a pad for computational reasons? There is a layer called **`Masking`** layer which will inform the RNN to ignore the fake values. \n",
    "\n",
    "❗️ However, if you look closely at the padded version of the first sequence:\n",
    "* There are padded zeros at the beginning of the sequence. \n",
    "    * 👩🏻‍🏫 It is better to pad the zeros at the end of the sequences with the argument `padding = 'post'`\n",
    "* But, there are also zeros **_in_** the heart-beat values. \n",
    "    * 🤨 How could the Neural Network know which zeros to keep and which zeros to ignore?\n",
    "    * 🧑🏻‍🏫 Instead of using 0 as a fake value by default, choose an absurd value that is easily detectable as fake, for example `value = -1`\n",
    "\n",
    "📚 [See the full documentation of ***pad_sequences*** here](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/sequence/pad_sequences)\n",
    "\n",
    "❓ **Questions** ❓ Now that you know how to use `pad_sequences`, let's re-do it properly one last time with the two additional arguments aforementioned:\n",
    "- `padding = 'post'`\n",
    "- `value = -1`\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🧪 If you padded properly, the shape of `X_pad` should be equal to $ (87554, 187) $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert X_pad.shape == (87554, 187)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "☝️ We are missing one dimension, the last one (corresponding to the number of features per observation)\n",
    "\n",
    "❓ **Question** ❓ To fix this issue, expand the last dimension using `expand_dims` function from `Numpy` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(X_pad.shape == (87554, 187, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1.4) Encoding the categorical targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c42605d020fd51885437f4af3cf10cebbeafc9bb"
   },
   "source": [
    "❓ **Question** ❓ The labels `y` have to be converted to one-hot-encoded categories. Transform `y` into categories using the appropriate Keras function and store the result into a variable called `y_cat`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) RNN modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7ae5108c9741b85f0f599cce51daf99df4733ed1"
   },
   "source": [
    "❓ **Question** ❓ Split your dataset (the electrocardiograms) between a train and test set (80/20 ratio)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5ddf1e7b397de3c413fc991945d2d7f09df67da1",
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2.1) GRU and LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "👉 In comparison with the previous challenge, each sequence comprises many observations (187 units of time), and your intuition should tell you that ALL of them matter to detect heart diseases (not just the most \"recent\" ones). \n",
    "\n",
    "🚀 The **LSTM (= Long Short Term Memory)** or the **GRU (= Gated Recurrent Unit)** model, with their ability to *avoid the vanishing gradient problem*, should be preferred over a SimpleRNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c4de23b85abe34a726eab268171da0e827bafa35"
   },
   "source": [
    "❓ **Question (RNN architecture)** ❓ \n",
    "* Write a model that has the following layers:\n",
    "    - a Masking layer whose `mask_value` corresponds to the value you decided to pad your data with (it is probably a negative value as suggested) - this layer will simply tell the network not to take into account the computation artifact\n",
    "    - two stacked `GRU` layers with 20 units each, and the `tanh` as the activation function\n",
    "    - a dense layer with 50 units\n",
    "    - a dropout layer with 20% drop\n",
    "    - a last (predictive) dense layer.\n",
    "* Print the summary of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Question (Training)** ❓ Compile and train your model. \n",
    "\n",
    "<u>Warning:</u> You will notice that it can take a very long time per epoch, even with GPUs. RNNs are, by nature, harder to distribute than CNNs. Indeed, GPUs work best when `trainable_params` is large (which is not the case here), or when `batch_size` is large.\n",
    "\n",
    "- To reduce the duration of each epoch, use a larger batch size (e.g 128)\n",
    "\n",
    "- Use also very small patience equal to 1 should be sufficient. This is because you have a lot of sequences and thus, many optimizations per epochs, even with a relatively large `batch_size`\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Question (Evaluation)** ❓ Evaluate your model on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (3) Baseline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🧑🏻‍🏫 ***In a classification task, a baseline model is to predict the most frequent class of the training set for all the elements in the test set.***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, what is the accuracy of a baseline model which would predict, for each ECG in `y_test`, the most probable category in `y_train` ? \n",
    "\n",
    "* 🎁 We wrote down below the code to compute the baseline accuracy of a multiclass classification task for you.\n",
    "    * 🧑🏻‍🎓 Make sure you understand the code\n",
    "* 🕵️‍♀️ Compare the baseline accuracy with the RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Training\" the baseline model\n",
    "\n",
    "occurencies_per_heartbeat_category_train = np.sum(y_train, axis=0)\n",
    "most_frequent_category_train = np.argmax(occurencies_per_heartbeat_category_train)\n",
    "\n",
    "# \"Evaluating\" the baseline model: in the test set, a baseline model will always predict\n",
    "# the most frequent class found in the train set\n",
    "\n",
    "occurencies_per_heartbeat_category_test = np.sum(y_test, axis=0)\n",
    "number_of_correct_predictions = occurencies_per_heartbeat_category_test[most_frequent_category_train]\n",
    "baseline_accuracy = number_of_correct_predictions/len(y_test)\n",
    "print(f'Baseline accuracy = {baseline_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "👆 Basically, the RNN that we designed earlier turns out to be as good/bad as a baseline model that predicts the most present category... \n",
    "\n",
    "🕵🏻 Let's try to deep dive into the predictions of the RNN model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "❓ **Question** ❓ Use the *predict* function to check what categories are predicted by the RNN model. Compare the distribution of the predictions with the distributions of the classes in the training set. What do you notice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🤨 The RNN model predicts frequencies that are extremely close to the original distribution of the heartbeats in the training set... Why is that?\n",
    "\n",
    "* The RNN was trained on a quite ***imbalanced dataset***. We could rebalance the dataset by downsampling the most represented category (normal heartbeats) and oversampling the under-represented categories... But that is not the focus of this chapter on RNN :)\n",
    "* ***Neural networks require bigger datasets***. The current dataset is *too small* for Neural Networks to learn noticeable facts from it.\n",
    "* Predicting the category of an ECG for one patient it not an easy task. ***We should have multiple ECGs for each patient to help the RNN learn the patterns of what a \"healthy ECG\" is***. Unfortunately, in this dataset, there is only ***one*** heartbeat per patient.\n",
    "\n",
    "❌ Do not try to improve the results here. \n",
    "\n",
    "🧑🏻‍🏫 One lesson that we have been teaching you and that we are going to repeat here again and again:\n",
    "* **Don't be satisfied with any \"good\" accuracy unless you have compared your model to a baseline model!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "\n",
    "🏁 Congratulations 🏁\n",
    "\n",
    "1. Download this notebook from your `Google Drive` or directly from `Google Colab`\n",
    "2. Drag-and-drop it from your `Downloads` folder to your local `[GITHUB_USERNAME]/data-challenges/06-Deep-Learning/04-Recurrent-Neural-Networks/02-Classify-Electrocardiograms`\n",
    "\n",
    "💾 Don't forget to push your code\n",
    "\n",
    "Follow the usual procedure on your terminal in the `06-Deep-Learning/04-Recurrent-Neural-Networks/02-Classify-Electrocardiograms` Classification folder:\n",
    "* *git add classify_electrocardiograms.ipynb*\n",
    "* *git commit -m \"I love RNN for ECG\"* or whatever meaningful message you want\n",
    "* *git push origin master*\n",
    "\n",
    "*Hint*: To find where this Colab notebook has been saved, click on File  Locate in Drive.\n",
    "\n",
    "🚀 It is time to move on to the *Air Pollution* challenge!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
