{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Markov Chains (Optional) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üí´ Imagine that your cat and yourself have a superpower: the power of teleportation üí´\n",
    "\n",
    "üê± Your cat Emily is quite young and is discovering her superpower. \n",
    "\n",
    "She can use it only in three cities:\n",
    "- üá´üá∑ Paris\n",
    "- üá¨üáß London\n",
    "- üá©üá™ Berlin\n",
    "\n",
    "And she can teleport herself from one city to the other only once per day!\n",
    "\n",
    "üò± Since you've been focusing on Le Wagon's Data Science challenges, you've just realised that you don't know where she's gone.\n",
    "\n",
    "üëâ However, based on some intuition, you \"know\" that:\n",
    "- from Paris, she will:\n",
    "    - stay in Paris tomorrow with probability 1/3\n",
    "    - move to London with probability 1/3\n",
    "    - move to Berlin with probability 1/3\n",
    "\n",
    "- from London, she will:\n",
    "    - move to Paris with probability 35%\n",
    "    - stay in London with probability 35%\n",
    "    - move to Berlin with probability 30%\n",
    "\n",
    "- from Berlin, she will:\n",
    "    - move to Paris with probability 15%\n",
    "    - move to London with probability 20%\n",
    "    - stay in Berlin tomorrow with probability 65%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üê± 1) Modelling the cat's movement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1) Draft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚úçÔ∏è Take a pen and a piece of paper to visualise Emily's moves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "   <summary>üëÄ Visual representation of this Markov Chain (try to do it yourself first !)</summary>\n",
    "\n",
    "<img src=\"https://github.com/lewagon/data-images/blob/master/math/markov_chains.png?raw=true\">\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚úàÔ∏è 1.2) Transitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll create for you the [`transition_matrix`](https://en.wikipedia.org/wiki/Stochastic_matrix) Q that represents these moves between `[\"paris\", \"london\", \"berlin\"]`\n",
    "\n",
    "\n",
    "If the probability of moving from `i` to `j` in one time step is $P(j|i) = P_{i,j}$, the transition matrix `Q` is given by using $P_{i,j}$ as the i-th row and j-th column element, e.g.,\n",
    "\n",
    "$${\\begin{bmatrix}P_{1,1}&P_{1,2}&\\dots &P_{1,j}&\\dots &P_{1,S}\\\\P_{2,1}&P_{2,2}&\\dots &P_{2,j}&\\dots &P_{2,S}\\\\\\vdots &\\vdots &\\ddots &\\vdots &\\ddots &\\vdots \\\\P_{i,1}&P_{i,2}&\\dots &P_{i,j}&\\dots &P_{i,S}\\\\\\vdots &\\vdots &\\ddots &\\vdots &\\ddots &\\vdots \\\\P_{S,1}&P_{S,2}&\\dots &P_{S,j}&\\dots &P_{S,S}\\\\\\end{bmatrix}}$$\n",
    "\n",
    "So for Emily, the transition matrix will be :\n",
    "\n",
    "$${\\begin{bmatrix}\n",
    "P_{Paris \\rightarrow Paris}&P_{Paris \\rightarrow London} &P_{Paris \\rightarrow Berlin}\\\\\n",
    "P_{London \\rightarrow Paris}&P_{London \\rightarrow London}&P_{London \\rightarrow Berlin}\\\\\n",
    "P_{Berlin \\rightarrow Paris}&P_{Berlin \\rightarrow London}&P_{Berlin \\rightarrow Berlin}\\\\\n",
    "\\end{bmatrix}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = np.array([\n",
    "    [1/3,1/3,1/3],\n",
    "    [0.35,0.35,0.3],\n",
    "    [0.15,0.2,0.65]])\n",
    "display(Q.shape)\n",
    "display(Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also called **`stochastic matrixes`**, these matrixes have a remarkable property: Each line is a **`probability vector`**, its coefficients sum up to 1 = 100%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëâ Let's imagine Emily started in Paris **initially**  \n",
    "We'll create an initial_position array (1 row  √ó  3 columns) storing those information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_position = np.array([[1,0,0]])\n",
    "display(initial_position)\n",
    "print(\"shape:\", initial_position.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì What the probability for Emily to be in paris/london/berlin in next step? Try to compute it, using dot products between\n",
    "- some slices of `Q`\n",
    "- and `initial_position`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba_paris_to_paris = None # one-liner dot product\n",
    "proba_paris_to_london = None # one-liner dot product\n",
    "proba_paris_to_berlin = None # one-liner dot product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Answer</summary>\n",
    "\n",
    "```python\n",
    "proba_paris_to_paris = initial_position.dot(Q[:,0])\n",
    "proba_paris_to_london = initial_position.dot(Q[:,1])\n",
    "proba_paris_to_berlin = initial_position.dot(Q[:,2])\n",
    "```\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ÑπÔ∏è Now, let's assume you don't know where your cat was last seen, but you have some initial guess: She's **initially**:\n",
    "- in Paris with a probability equal to 30%\n",
    "- in London with a probability equal to 40%\n",
    "- in Berlin with a probability equal to 30%\n",
    "\n",
    "‚ùì Create your (1,3) array of `initial_position`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Compute the $ (1,3) $ array of probabilities `day_1` of the cat being in each city on ***day 1*** with an elegant math formula ‚ùì\n",
    "\n",
    "<br>\n",
    "\n",
    "<details>\n",
    "    <summary markdown='span'>üëÄ Hints</summary>\n",
    "\n",
    "Vizualize your matrix product \n",
    "<img src='https://github.com/lewagon/data-images/blob/master/math/vector_dot_matrix.jpeg?raw=true'>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary markdown='span'>Answer</summary>\n",
    "\n",
    "üìö To compute the (1,3) probabilities of the cat being in each city on ***day 1***:, you can matrix-multiply the (1,3) `initial_position` by the (3,3) `transition_matrix`!\n",
    "\n",
    "üëâ We will admit this ***update rule*** for this challenge, but try to convince yourself why it's the case by playing around in various simple cases!\n",
    "    \n",
    "ü§ì If you really want more explanations about this update rule, you can check [Cambridge University - Markov Chains](http://www.statslab.cam.ac.uk/~rrw1/markov/M.pdf) but that is clearly not the goal of this bootcamp. So just accept the rule - trust us - and follow the notebook step-by-step.\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì What is the probability that Emily will be in Paris on day 2 ? What about London and Berlin ‚ùì"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚è≥ 1.3) Where is the cat *n* days later ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Create a function `emily` which computes the probabilities of Emily being in Paris, Berlin and London after `n_days`‚ùì\n",
    "\n",
    "* `Inputs` : `initial_position`, `transition_matrix` and `n_days`\n",
    "* `Output` : probabilities of each city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emily(initial_position, transition_matrix, n_days):\n",
    "    pass  # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì So, where will Emily be in 100 days ‚ùì"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìà 1.4) Visualising the probabilities overtime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Plot the probabilities of being in each city over time\n",
    "\n",
    "üòâ This last question is non-guided !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emily_over_time(initial_position, transition_matrix, n_days):\n",
    "    pass  # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü•° 2) Takeaways"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ù§Ô∏è After `Emily in Paris`, we'll most likely have `Emily in Berlin` in the long run !\n",
    "\n",
    "‚ùóÔ∏è ***Not all the Markov Chains converge to a stable state ‚ùóÔ∏è*** Think about a hamster who lives between two states 0 and 1 and moves from one to the other with probability 1 each day ! \n",
    "\n",
    "üí° Did you know? \n",
    "- Google computes the probability that from one page, you click on other pages ! \n",
    "- Its secret algorithm is based on Markov Chains (and of course advanced refinements which made the founders billionaires...!)\n",
    "- üìö `Google Search Engine` : [Analytics Vidhya article - Google Page Rank and Markov Chains](https://medium.com/analytics-vidhya/google-page-rank-and-markov-chains-d65717b98f9c)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üèÅ Congratulations !\n",
    "\n",
    "üíæ Do not forget to `git add/commit/push`\n",
    "\n",
    "üòÅ No panic if Markov Chains are still not clear for you. This challenge was more like an introduction to this topic, however for Data Analyst and Junior Data Scientists, you won't need necessarily use it :) \n",
    "\n",
    "ü•≥ Consider that it was a good opportunity to manipulate tools from `Linear Algebra` such as `matrixes` and tools from `Probabilty Theory` such as `probability distributions` !"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
