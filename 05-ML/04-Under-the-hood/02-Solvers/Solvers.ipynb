{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solvers ‚öôÔ∏è"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, you will investigate the effects of different `solvers` on `LogisticRegression` models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëá Run the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.47</td>\n",
       "      <td>5.97</td>\n",
       "      <td>7.36</td>\n",
       "      <td>10.17</td>\n",
       "      <td>6.84</td>\n",
       "      <td>9.15</td>\n",
       "      <td>9.78</td>\n",
       "      <td>9.52</td>\n",
       "      <td>10.34</td>\n",
       "      <td>8.80</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.05</td>\n",
       "      <td>8.84</td>\n",
       "      <td>9.76</td>\n",
       "      <td>8.38</td>\n",
       "      <td>10.15</td>\n",
       "      <td>6.91</td>\n",
       "      <td>9.70</td>\n",
       "      <td>9.01</td>\n",
       "      <td>9.23</td>\n",
       "      <td>8.80</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.59</td>\n",
       "      <td>10.71</td>\n",
       "      <td>10.84</td>\n",
       "      <td>10.97</td>\n",
       "      <td>9.03</td>\n",
       "      <td>10.42</td>\n",
       "      <td>11.46</td>\n",
       "      <td>11.25</td>\n",
       "      <td>11.34</td>\n",
       "      <td>9.06</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.00</td>\n",
       "      <td>8.44</td>\n",
       "      <td>8.32</td>\n",
       "      <td>9.65</td>\n",
       "      <td>7.87</td>\n",
       "      <td>10.92</td>\n",
       "      <td>6.97</td>\n",
       "      <td>11.07</td>\n",
       "      <td>10.66</td>\n",
       "      <td>8.89</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.12</td>\n",
       "      <td>13.44</td>\n",
       "      <td>10.35</td>\n",
       "      <td>9.95</td>\n",
       "      <td>11.09</td>\n",
       "      <td>9.38</td>\n",
       "      <td>10.22</td>\n",
       "      <td>9.04</td>\n",
       "      <td>7.68</td>\n",
       "      <td>11.38</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0           9.47              5.97         7.36           10.17       6.84   \n",
       "1          10.05              8.84         9.76            8.38      10.15   \n",
       "2          10.59             10.71        10.84           10.97       9.03   \n",
       "3          11.00              8.44         8.32            9.65       7.87   \n",
       "4          12.12             13.44        10.35            9.95      11.09   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density  sulphates  alcohol  \\\n",
       "0                 9.15                  9.78     9.52      10.34     8.80   \n",
       "1                 6.91                  9.70     9.01       9.23     8.80   \n",
       "2                10.42                 11.46    11.25      11.34     9.06   \n",
       "3                10.92                  6.97    11.07      10.66     8.89   \n",
       "4                 9.38                 10.22     9.04       7.68    11.38   \n",
       "\n",
       "   quality rating  \n",
       "0               6  \n",
       "1               7  \n",
       "2               4  \n",
       "3               8  \n",
       "4               3  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"data.csv\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The dataset consists of different wines üç∑\n",
    "- The features describe different properties of the wines \n",
    "- The target üéØ is a quality rating given by an expert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Target engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, you are going to transform the ratings into a binary target."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëá How many observations are there for each rating?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6,  7,  4,  8,  3,  1,  2, 10,  5,  9])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['quality rating'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "delete"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10    10143\n",
       "5     10124\n",
       "1     10090\n",
       "2     10030\n",
       "8      9977\n",
       "6      9961\n",
       "9      9955\n",
       "7      9954\n",
       "4      9928\n",
       "3      9838\n",
       "Name: quality rating, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['quality rating'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëá Create `y` by transforming the target into a binary classification task where quality ratings below 6 are bad [0], and ratings of 6 and above are good [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "y = df['quality rating'].map(lambda x: 0 if x < 6 else 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëá Check the class balance of the new binary target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    50010\n",
       "1    49990\n",
       "Name: quality rating, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create your `X` by scaling the features. This will allow for fair comparison of different solvers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# Select only the features \n",
    "X = df.drop(columns=['quality rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Fit scaler to features\n",
    "scaler = MinMaxScaler().fit(X)\n",
    "\n",
    "# Scale features\n",
    "X_scaled = scaler.transform(X)\n",
    "\n",
    "# keep column names\n",
    "X_scaled = pd.DataFrame(X_scaled)\n",
    "X_scaled.columns = X.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. LogisticRegression solvers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëá Logistic Regression models can be optimized using different **solvers**. Find out \n",
    "- Which is the `fastest_solver` ?\n",
    "- What can you say about their respective precision score?\n",
    "\n",
    "`solvers = ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']`\n",
    " \n",
    "For more information on these 5 solvers, check out [this stackoverflow thread](https://stackoverflow.com/questions/38640109/logistic-regression-python-solvers-defintions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision score</th>\n",
       "      <th>fit time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>newton-cg</th>\n",
       "      <td>0.874386</td>\n",
       "      <td>0.422900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lbfgs</th>\n",
       "      <td>0.874389</td>\n",
       "      <td>0.382583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>liblinear</th>\n",
       "      <td>0.874449</td>\n",
       "      <td>0.244008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sag</th>\n",
       "      <td>0.874381</td>\n",
       "      <td>0.579548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>saga</th>\n",
       "      <td>0.874386</td>\n",
       "      <td>1.144593</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           precision score  fit time\n",
       "newton-cg         0.874386  0.422900\n",
       "lbfgs             0.874389  0.382583\n",
       "liblinear         0.874449  0.244008\n",
       "sag               0.874381  0.579548\n",
       "saga              0.874386  1.144593"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# List solver types to loop over\n",
    "solvers = ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "\n",
    "# Initiate scores and fit times lists to store for each model\n",
    "scores = []\n",
    "fit_times = []\n",
    "\n",
    "# Loop over solvers\n",
    "for solver in solvers:\n",
    "    \n",
    "    # Cross validate each model\n",
    "    cv_log_s = cross_validate(LogisticRegression(solver=solver),\n",
    "                    X_scaled, y,\n",
    "                    cv = 5,\n",
    "                    scoring = ['precision'])\n",
    "    \n",
    "    # Append mean score and mean fit time to lists\n",
    "    scores.append(cv_log_s['test_precision'].mean())\n",
    "    fit_times.append(cv_log_s['fit_time'].mean())\n",
    "    \n",
    "# Create dataframe with each model's performance\n",
    "solvers_performance = pd.DataFrame({\"precision score\":scores, \"fit time\": fit_times}, index = solvers)\n",
    "solvers_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR ANSWER\n",
    "fastest_solver = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": [
     "delete"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'liblinear'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fastest_solver = solvers_performance['fit time'].idxmin()\n",
    "fastest_solver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>‚òùÔ∏è Intuition</summary>\n",
    "\n",
    "All solvers should produce similar precision scores because our cost-function is \"easy\" enough to have a global minimum which is found by all 5 solvers. For very complex cost-functions such as in Deep Learning, different solvers may stopping at different values of the loss function. \n",
    "\n",
    "</details> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  üß™ Test your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.8.10, pytest-7.1.2, pluggy-1.0.0 -- /bin/python3\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/quantium/labs/lewagon/data-challenges/05-ML/04-Under-the-hood/02-Solvers/tests\n",
      "plugins: dash-1.19.0, anyio-3.6.1\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 1 item\n",
      "\n",
      "test_solvers.py::TestSolvers::test_fastest_solver \u001b[32mPASSED\u001b[0m\u001b[32m                 [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m1 passed\u001b[0m\u001b[32m in 0.01s\u001b[0m\u001b[32m ===============================\u001b[0m\n",
      "\n",
      "\n",
      "üíØ You can commit your code:\n",
      "\n",
      "\u001b[1;32mgit\u001b[39m add tests/solvers.pickle\n",
      "\n",
      "\u001b[32mgit\u001b[39m commit -m \u001b[33m'Completed solvers step'\u001b[39m\n",
      "\n",
      "\u001b[32mgit\u001b[39m push origin master\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "result = ChallengeResult('solvers',\n",
    "                         fastest_solver=fastest_solver\n",
    "                         )\n",
    "result.write()\n",
    "print(result.check())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression models can also be optimized via Stochastic Gradient Descent.\n",
    "\n",
    "üëá Evaluate a Logistic Regression model optimized via **Stochastic Gradient Descent**. How do its precision score and training time compare to the performance of the models trained in section 2.?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<details>\n",
    "<summary>üí° Hint</summary>\n",
    "\n",
    "- If you are stuck, look at the [SGDClassifier doc](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html)!\n",
    "\n",
    "</details>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/quantium/.local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/home/quantium/.local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/home/quantium/.local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/home/quantium/.local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/home/quantium/.local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd_model = SGDClassifier(loss=\"log\")\n",
    "\n",
    "cv_sgd = cross_validate(sgd_model,\n",
    "                        X_scaled, y,\n",
    "                        cv = 5,\n",
    "                        scoring = 'precision')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": [
     "delete"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.861819322296774"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Precision Score\n",
    "cv_sgd['test_score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": [
     "delete"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20602355003356934"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training time\n",
    "cv_sgd['fit_time'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚òùÔ∏è The SGD model should have the shortest training time, for similar performance. This is a direct effect of performing each epoch of the Gradient Descent on a single data point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëá Use the best model to predict the binary quality (0 or 1) of the following wine. Store your\n",
    "- `predicted_class`\n",
    "- `predicted_proba_of_class`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.54</td>\n",
       "      <td>13.5</td>\n",
       "      <td>12.35</td>\n",
       "      <td>8.78</td>\n",
       "      <td>14.72</td>\n",
       "      <td>9.06</td>\n",
       "      <td>9.67</td>\n",
       "      <td>10.15</td>\n",
       "      <td>11.17</td>\n",
       "      <td>12.17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0           9.54              13.5        12.35            8.78      14.72   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density  sulphates  alcohol  \n",
       "0                 9.06                  9.67    10.15      11.17    12.17  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data = pd.read_csv('new_data.csv')\n",
    "\n",
    "new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/quantium/.local/lib/python3.8/site-packages/sklearn/linear_model/_stochastic_gradient.py:173: FutureWarning: The loss 'log' was deprecated in v1.1 and will be removed in version 1.3. Use `loss='log_loss'` which is equivalent.\n",
      "  warnings.warn(\n",
      "/home/quantium/.local/lib/python3.8/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but SGDClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model with fastest training time\n",
    "best_model = SGDClassifier(loss=\"log\").fit(X_scaled,y)\n",
    "\n",
    "# Scale new data using original scaler\n",
    "new_X = scaler.transform(new_data)\n",
    "\n",
    "# Predict!\n",
    "best_model.predict(new_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": [
     "delete"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/quantium/.local/lib/python3.8/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but SGDClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_class = best_model.predict(new_X)[0]\n",
    "predicted_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": [
     "delete"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/quantium/.local/lib/python3.8/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but SGDClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9602965677202447"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_proba_of_class = best_model.predict_proba(new_X)[0, predicted_class]\n",
    "predicted_proba_of_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üèÅ  Check your code and push your notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.8.10, pytest-7.1.2, pluggy-1.0.0 -- /bin/python3\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/quantium/labs/lewagon/data-challenges/05-ML/04-Under-the-hood/02-Solvers/tests\n",
      "plugins: dash-1.19.0, anyio-3.6.1\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 2 items\n",
      "\n",
      "test_new_data_prediction.py::TestNewDataPrediction::test_predicted_class \u001b[32mPASSED\u001b[0m\u001b[32m [ 50%]\u001b[0m\n",
      "test_new_data_prediction.py::TestNewDataPrediction::test_predicted_proba \u001b[32mPASSED\u001b[0m\u001b[32m [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m2 passed\u001b[0m\u001b[32m in 0.11s\u001b[0m\u001b[32m ===============================\u001b[0m\n",
      "\n",
      "\n",
      "üíØ You can commit your code:\n",
      "\n",
      "\u001b[1;32mgit\u001b[39m add tests/new_data_prediction.pickle\n",
      "\n",
      "\u001b[32mgit\u001b[39m commit -m \u001b[33m'Completed new_data_prediction step'\u001b[39m\n",
      "\n",
      "\u001b[32mgit\u001b[39m push origin master\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "result = ChallengeResult('new_data_prediction',\n",
    "    predicted_class=predicted_class,\n",
    "    predicted_proba_of_class=predicted_proba_of_class\n",
    ")\n",
    "result.write()\n",
    "print(result.check())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
