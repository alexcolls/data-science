{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workflow & Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy import stats\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üè† Import the house price data set. We will keep only numerical features for the sake of simplicity\n",
    "\n",
    "üéØ Your goal will be to fit the best KNN Regressor. In particular, how many \"neighbors\" (<font color=blue>K</font> in <font color=blue>K</font>NN) should you consider to get the best predictions for your house prices ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>...</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003</td>\n",
       "      <td>196.0</td>\n",
       "      <td>706</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1976</td>\n",
       "      <td>1976</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978</td>\n",
       "      <td>...</td>\n",
       "      <td>298</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2001</td>\n",
       "      <td>2002</td>\n",
       "      <td>162.0</td>\n",
       "      <td>486</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1915</td>\n",
       "      <td>1970</td>\n",
       "      <td>0.0</td>\n",
       "      <td>216</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>272</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>350.0</td>\n",
       "      <td>655</td>\n",
       "      <td>...</td>\n",
       "      <td>192</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>1456</td>\n",
       "      <td>60</td>\n",
       "      <td>62.0</td>\n",
       "      <td>7917</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1999</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2007</td>\n",
       "      <td>175000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>1457</td>\n",
       "      <td>20</td>\n",
       "      <td>85.0</td>\n",
       "      <td>13175</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1978</td>\n",
       "      <td>1988</td>\n",
       "      <td>119.0</td>\n",
       "      <td>790</td>\n",
       "      <td>...</td>\n",
       "      <td>349</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2010</td>\n",
       "      <td>210000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>1458</td>\n",
       "      <td>70</td>\n",
       "      <td>66.0</td>\n",
       "      <td>9042</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>1941</td>\n",
       "      <td>2006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>275</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2500</td>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>266500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>1459</td>\n",
       "      <td>20</td>\n",
       "      <td>68.0</td>\n",
       "      <td>9717</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1950</td>\n",
       "      <td>1996</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49</td>\n",
       "      <td>...</td>\n",
       "      <td>366</td>\n",
       "      <td>0</td>\n",
       "      <td>112</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>142125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>1460</td>\n",
       "      <td>20</td>\n",
       "      <td>75.0</td>\n",
       "      <td>9937</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1965</td>\n",
       "      <td>1965</td>\n",
       "      <td>0.0</td>\n",
       "      <td>830</td>\n",
       "      <td>...</td>\n",
       "      <td>736</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2008</td>\n",
       "      <td>147500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1121 rows √ó 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Id  MSSubClass  LotFrontage  LotArea  OverallQual  OverallCond  \\\n",
       "0        1          60         65.0     8450            7            5   \n",
       "1        2          20         80.0     9600            6            8   \n",
       "2        3          60         68.0    11250            7            5   \n",
       "3        4          70         60.0     9550            7            5   \n",
       "4        5          60         84.0    14260            8            5   \n",
       "...    ...         ...          ...      ...          ...          ...   \n",
       "1455  1456          60         62.0     7917            6            5   \n",
       "1456  1457          20         85.0    13175            6            6   \n",
       "1457  1458          70         66.0     9042            7            9   \n",
       "1458  1459          20         68.0     9717            5            6   \n",
       "1459  1460          20         75.0     9937            5            6   \n",
       "\n",
       "      YearBuilt  YearRemodAdd  MasVnrArea  BsmtFinSF1  ...  WoodDeckSF  \\\n",
       "0          2003          2003       196.0         706  ...           0   \n",
       "1          1976          1976         0.0         978  ...         298   \n",
       "2          2001          2002       162.0         486  ...           0   \n",
       "3          1915          1970         0.0         216  ...           0   \n",
       "4          2000          2000       350.0         655  ...         192   \n",
       "...         ...           ...         ...         ...  ...         ...   \n",
       "1455       1999          2000         0.0           0  ...           0   \n",
       "1456       1978          1988       119.0         790  ...         349   \n",
       "1457       1941          2006         0.0         275  ...           0   \n",
       "1458       1950          1996         0.0          49  ...         366   \n",
       "1459       1965          1965         0.0         830  ...         736   \n",
       "\n",
       "      OpenPorchSF  EnclosedPorch  3SsnPorch  ScreenPorch  PoolArea  MiscVal  \\\n",
       "0              61              0          0            0         0        0   \n",
       "1               0              0          0            0         0        0   \n",
       "2              42              0          0            0         0        0   \n",
       "3              35            272          0            0         0        0   \n",
       "4              84              0          0            0         0        0   \n",
       "...           ...            ...        ...          ...       ...      ...   \n",
       "1455           40              0          0            0         0        0   \n",
       "1456            0              0          0            0         0        0   \n",
       "1457           60              0          0            0         0     2500   \n",
       "1458            0            112          0            0         0        0   \n",
       "1459           68              0          0            0         0        0   \n",
       "\n",
       "      MoSold  YrSold  SalePrice  \n",
       "0          2    2008     208500  \n",
       "1          5    2007     181500  \n",
       "2          9    2008     223500  \n",
       "3          2    2006     140000  \n",
       "4         12    2008     250000  \n",
       "...      ...     ...        ...  \n",
       "1455       8    2007     175000  \n",
       "1456       2    2010     210000  \n",
       "1457       5    2010     266500  \n",
       "1458       4    2010     142125  \n",
       "1459       6    2008     147500  \n",
       "\n",
       "[1121 rows x 38 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load raw data\n",
    "data = pd.read_csv('https://wagon-public-datasets.s3.amazonaws.com/houses_train_raw.csv')\n",
    "\n",
    "# Only keep numerical columns and raws without NaN\n",
    "data = data.select_dtypes(include=np.number).dropna()\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(columns=['SalePrice'])\n",
    "y = data['SalePrice']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Train/Test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question (Holdout)**‚ùì\n",
    "\n",
    "üëá Split the dataset to create your `X_train` `X_test` and `y_train` `y_test`. Use:\n",
    "- `test_size=0.3`\n",
    "- `random_state=0` to compare your results with your buddy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚öñÔ∏è Scaling is always crucially important for the KNN algorithm..\n",
    "\n",
    "‚ùì **Question (Scaling)** ‚ùì \n",
    "\n",
    "* Scale your train set and test set.\n",
    "* Here, let's simply apply the `StandardScaler` and not waste time choosing one scaler per feature. Indeed, the goals of this exercise are to:\n",
    "    * review KNN\n",
    "    * understand GridSearchCV\n",
    "    * understand RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 37)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_scaler = StandardScaler()\n",
    "r_scaler.fit(X_train)\n",
    "X_train_scaled = r_scaler.transform(X_train)\n",
    "X_train_scaled = pd.DataFrame(data=X_train_scaled, columns = X.columns)\n",
    "X_train_scaled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Baseline KNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question (A baseline for our KNN)** ‚ùì\n",
    "\n",
    "Cross-validate (*cv = 5*) a simple KNN regressor taking into account only _the closest neighbor_, and compute the average score over the 5 folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.569025195507008"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neigh = KNeighborsRegressor(n_neighbors=1)\n",
    "\n",
    "cv_results = cross_validate(neigh, X_train_scaled, y_train, cv=5)\n",
    "base_knn_score = cv_results['test_score'].mean()\n",
    "base_knn_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. GridSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. A first GridSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question (GridSearch v1)**‚ùì\n",
    "\n",
    "Let's use SKLearn `GridSearchCV` to find the best KNN hyperparameter `n_neighbors`.\n",
    "- Start a coarse-grain approach, with `n_neighbors` = [1,5,10,20,50]\n",
    "- 5-fold cross-validate each parameter\n",
    "- Make sure to maximize your performance time using `n_jobs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# Instanciate model\n",
    "model = KNeighborsRegressor()\n",
    "\n",
    "# Hyperparameter Grid\n",
    "grid = {'n_neighbors': [1,5,10,20,50]}\n",
    "\n",
    "# Instanciate Grid Search\n",
    "search = GridSearchCV(model, grid, scoring = 'r2', cv = 10, n_jobs=-1 ) \n",
    "\n",
    "# Fit data to Grid Search\n",
    "search.fit(X_train_scaled,y_train);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question (best parameters)** ‚ùì\n",
    "\n",
    "According to the GridSearch, what is the optimal K value?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 20}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_k = search.best_params_\n",
    "best_k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question (scoring)** ‚ùì What is the best score the optimal K value produced?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7685936824413232"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_score = search.best_score_\n",
    "best_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question (GridSearch V2)** ‚ùì\n",
    "\n",
    "\n",
    "Now, we have an idea about where the best $K$ lies, but some of the values we didn't try could result in a  better performance.\n",
    "\n",
    "* Re-run a GridSearch trying some values for $K$ around to your previous best value\n",
    "* What are the `best_score` and `best_k` for this refined GridSearch?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. A second GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate model\n",
    "model = KNeighborsRegressor()\n",
    "\n",
    "# Hyperparameter Grid\n",
    "grid = {'n_neighbors': [13,14,15,16,17]}\n",
    "\n",
    "# Instantiate Grid Search\n",
    "search = GridSearchCV(model, grid, scoring = 'r2', cv=10, n_jobs=-1 ) \n",
    "\n",
    "# Fit data to Grid Search\n",
    "search.fit(X_train_scaled,y_train);\n",
    "\n",
    "best_k = search.best_params_['n_neighbors']\n",
    "best_k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7724899314806318"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_score = search.best_score_\n",
    "best_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***üß™ Test your code***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.8.10, pytest-7.1.2, pluggy-1.0.0 -- /bin/python3\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/quantium/labs/lewagon/data-challenges/05-ML/05-Model-Tuning/01-Workflow/tests\n",
      "plugins: dash-1.19.0, anyio-3.6.1\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 2 items\n",
      "\n",
      "test_knn.py::TestKnn::test_best_k \u001b[32mPASSED\u001b[0m\u001b[32m                                 [ 50%]\u001b[0m\n",
      "test_knn.py::TestKnn::test_best_score \u001b[32mPASSED\u001b[0m\u001b[32m                             [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m2 passed\u001b[0m\u001b[32m in 0.15s\u001b[0m\u001b[32m ===============================\u001b[0m\n",
      "\n",
      "\n",
      "üíØ You can commit your code:\n",
      "\n",
      "\u001b[1;32mgit\u001b[39m add tests/knn.pickle\n",
      "\n",
      "\u001b[32mgit\u001b[39m commit -m \u001b[33m'Completed knn step'\u001b[39m\n",
      "\n",
      "\u001b[32mgit\u001b[39m push origin master\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nbresult import ChallengeResult\n",
    "result = ChallengeResult('knn',\n",
    "                         best_k=best_k,\n",
    "                         best_score=best_score)\n",
    "result.write()\n",
    "print(result.check())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Visual check (manual GridSearch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚òùÔ∏è This problem is actually simple enough to perform a GridSearch manually.\n",
    "\n",
    "‚ùì **Question(Manual GridSearch)** ‚ùì\n",
    "\n",
    "- Loop manually over all values of $K$ from $1$ to $50$ and store the average of the cross-validated scores of each model in a list.\n",
    "- Plot the scores as a function of $K$ to visually find the best $K$ using the `Elbow Method`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = 50\n",
    "Ks = []\n",
    "for i in range(1, n+1):\n",
    "    model = KNeighborsRegressor(n_neighbors=i)\n",
    "    cv_results = cross_validate(model, X_train_scaled, y_train, cv=10, n_jobs=-1)\n",
    "    Ks.append(cv_results['test_score'].mean())\n",
    "\n",
    "plt.scatter(x=range(1, n+1), y=Ks);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùìCan you guess what makes GridSearchCV a better option than such manual loop ?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Answer</summary>\n",
    "\n",
    "- Sklearn's `n_jobs=-1` allows you to paralellize the search, utilizing all of your CPU cores\n",
    "- What if you had multiple hyper-parameters to co-optimize?\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. GridSearch with multiple parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üë©üèª‚Äçüè´ KNNRegressor suppports various _distance metrics_ via the hyper-parameter `p` \n",
    "\n",
    "üìö [sklearn.neighbors.KNeighborsRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html)\n",
    "\n",
    "‚ùì **Question (tuning multiple parameters)** ‚ùì\n",
    "\n",
    "\n",
    "* Use GridSearchCV to search for the best $K$ and $p$ simultaneously.\n",
    "    * Try all combinations for $K = [1, 5, 10, 20, 50]$ and $p = [1, 2, 3]$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate model\n",
    "model = KNeighborsRegressor()\n",
    "\n",
    "# Hyperparameter Grid\n",
    "grid = {'n_neighbors': [1,5,10,20,50], 'p': [1, 2, 3]}\n",
    "\n",
    "# Instantiate Grid Search\n",
    "search = GridSearchCV(model, grid, scoring = 'r2', cv=10, n_jobs=-1 ) \n",
    "\n",
    "# Fit data to Grid Search\n",
    "search.fit(X_train_scaled,y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question (number of submodels)**‚ùì\n",
    "\n",
    "How many submodels did you train overall?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Hint</summary>\n",
    "\n",
    "Much more than 15. Think twice :)\n",
    "    <details>\n",
    "    <summary>Answer</summary>\n",
    "\n",
    "75 models due to CV=5\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import product\n",
    "\n",
    "len(list(product(grid['n_neighbors'], grid['p'])))*5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question (best parameters and best score after tuning the model with multiple parameters)**‚ùì\n",
    "\n",
    "What are the *best parameters* and the *best score*?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 2, 'p': 1}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params = search.best_params_\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8107808834152845"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_score = search.best_score_\n",
    "best_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Random Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see whether a RandomizedSearch can find a better combination with the same number of models being fitted.\n",
    "\n",
    "‚ùì **Question (RandomizedSearchCV)** ‚ùì\n",
    "\n",
    "Use `RandomizedSearchCV` to\n",
    "- Randomly sample $K$ from a uniform `randint(1,50)` distribition\n",
    "- Sample $p$ from a list $[1,2,3]$\n",
    "- Use the correct numbers of `n_iter` and `cv` to fit the exact same numbers of models as in your previous GridSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# Instantiate model\n",
    "model = KNeighborsRegressor()\n",
    "\n",
    "# Hyperparameter Grid\n",
    "grid = {'n_neighbors': range(1,51), 'p': [1, 2, 3]}\n",
    "\n",
    "# Instantiate Grid Search\n",
    "search = RandomizedSearchCV(model, grid, scoring = 'r2', cv=10, n_jobs=-1 ) \n",
    "\n",
    "# Fit data to Grid Search\n",
    "search.fit(X_train_scaled,y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 2, 'p': 1}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params = search.best_params_\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8107808834152845"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_score = search.best_score_\n",
    "best_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Generalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question (finetuning your model one more time)**‚ùì\n",
    "\n",
    "- Refine your RandomsearchCV if you want\n",
    "- Choose your best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "X_test_scaled = r_scaler.transform(X_test)\n",
    "\n",
    "best_model = search.best_estimator_\n",
    "best_model.fit(X_train_scaled, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now try to display your `cv_results` as a `DataFrame`, this will help you visualize what's going on inside the CV! üòâ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.00384569, 0.00337863, 0.0040226 , 0.00411272, 0.0135386 ,\n",
       "        0.00424862, 0.00442839, 0.0038693 , 0.00392294, 0.00389767]),\n",
       " 'score_time': array([0.04136753, 0.0404551 , 0.00606394, 0.00562406, 0.00546336,\n",
       "        0.00523376, 0.00760508, 0.00520349, 0.00483108, 0.00458837]),\n",
       " 'test_score': array([0.80759144, 0.52120046, 0.78580166, 0.78559314, 0.55210938,\n",
       "        0.79363315, 0.8578987 , 0.85175014, 0.86902272, 0.62000474])}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results = cross_validate(model, X_train_scaled, y_train, cv=10, n_jobs=-1)\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question (Evaluation of the \"best\" model)** ‚ùì\n",
    "\n",
    "* Time has come to discover our model's performance with \"best params\" on the **unseen** test set `X_test`.\n",
    "    * Compute the r2 score for the test set and save it as `r2_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/quantium/.local/lib/python3.8/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but KNeighborsRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7501375248102157"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "r2_test = r2_score(y_test, best_model.predict(r_scaler.transform(X_test)))\n",
    "r2_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question (Taking a step back)** ‚ùì\n",
    "\n",
    "Would you consider the optimized model to generalize well?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Answer</summary>\n",
    "\n",
    "Test score may decrease a bit with train set. Probably not more than 5%. This can be due to\n",
    "- A non-representative train/test split\n",
    "- A cross-val number too small leading to overfitting the model-tuning phase. The more you cross-validated, the more robust your findings will generalize - but you can't increase cv too much if your dataset is too small as you won't keep enough observations in each fold to be representative.\n",
    "- Our dataset is very small and our hyperparameter optimization is thus extremely dependent (and overfitting) on our train/test split. Always make sure your dataset is much bigger than the total number of hyperparameter combinations you are trying out!\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***üß™ Test your code***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform linux -- Python 3.8.10, pytest-7.1.2, pluggy-1.0.0 -- /bin/python3\n",
      "cachedir: .pytest_cache\n",
      "rootdir: /home/quantium/labs/lewagon/data-challenges/05-ML/05-Model-Tuning/01-Workflow/tests\n",
      "plugins: dash-1.19.0, anyio-3.6.1\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 1 item\n",
      "\n",
      "test_r2.py::TestR2::test_r2 \u001b[32mPASSED\u001b[0m\u001b[32m                                       [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m1 passed\u001b[0m\u001b[32m in 0.19s\u001b[0m\u001b[32m ===============================\u001b[0m\n",
      "\n",
      "\n",
      "üíØ You can commit your code:\n",
      "\n",
      "\u001b[1;32mgit\u001b[39m add tests/r2.pickle\n",
      "\n",
      "\u001b[32mgit\u001b[39m commit -m \u001b[33m'Completed r2 step'\u001b[39m\n",
      "\n",
      "\u001b[32mgit\u001b[39m push origin master\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nbresult import ChallengeResult\n",
    "result = ChallengeResult('r2', \n",
    "                         r2_test=r2_test)\n",
    "result.write()\n",
    "print(result.check())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üèÅ Congratulations! Now, you know how to finetune a model using either a GridSearchCV or a RandomizedSearchCV \n",
    "\n",
    "üíæ Don't forget to¬†`git add/commit/push`¬†your notebook...\n",
    "\n",
    "üöÄ ... and move on to the next challenge!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
