{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus: The `Cars Price` dataset revisited"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üßëüèª‚Äçüç≥ During **`Machine Learning > 02 - Prepare the Dataset`**, we discovered that to run Machine Learning Algorithms properly, you need to feed them with ***cleaned datasets***."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>üìù <i>Reminders about the Data Preprocessing Workflow</i> üìù</summary>\n",
    "\n",
    "1. üß≠ ***Exploratory Data Analysis***\n",
    "2. üë• Remove ***Duplicates***\n",
    "3. ü§ï Impute or Remove ***Missing Values***\n",
    "4. üïµüèª‚Äç‚ôÇÔ∏è Check for ***Outliers***\n",
    "5. üìè ***Scaling*** Numerical Features\n",
    "6. üè∑ ***One-Hot-Encoder*** for Categorical Features \n",
    "7. üëª ***Label-Encoder*** for a Categorical Target\n",
    "8. üç∞ ***Feature Engineering*** will squeeze out better signals for your model to learn\n",
    "feature instead_\n",
    "9. üç∞ ***Target Engineering***: might be easier to predict a transformed target\n",
    "    \n",
    "10. ‚ò†Ô∏è Not all features are our friends. Remove the \"noisy\" features using ***Feature Permutation*** (or ***VIF Analysis*** for Linear models)\n",
    "\n",
    "<u> Additional Notes</u>    \n",
    "    \n",
    "- _Example of Feature Engineering: if you have the length and the width of a flat, you would maybe create the surface by multiplying the length by the width_\n",
    "\n",
    "- _Example of Target Engineering: if you look to predict the price of a stock in the next day, it might be easier to predict the %increase rather than the absolute value. If you look at house prices, you may want to predict the logarithm of their values and then exponentiate the predictions_\n",
    "\n",
    "- By \"noisy\" features, we mean :\n",
    "    - either a feature that doesn't bring anything to the prediction in a sense that when you shuffle this feature, it doesn't affect the performance of your model\n",
    "    - or a feature that is built using other features (strong linear relationship)\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üöó We had  already worked on a simplified version of the *Cars' Price* dataset. \n",
    "\n",
    "üéØ The goal of this recap is to build an optimal pipeline to ***predict the price of cars according to their specificities***:\n",
    "\n",
    "1. We will need a *Preprocessing Pipeline*...\n",
    "2. ... that we can *chain with a Scikit-Learn Estimator*\n",
    "3. And go further by:\n",
    "    - running a *FeaturePermutation*\n",
    "    - optimizing the hyperparameters with a *GridSearchCV* or a *RandomizedSearchCV*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA MANIPULATION\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option(\"max_columns\",None) # Show all columns of a Pandas DataFrame\n",
    "\n",
    "# DATA VISUALISATION\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# STATISTICS\n",
    "from statsmodels.graphics.gofplots import qqplot\n",
    "# This function plots your sample distribution against a Normal distribution, \n",
    "# to check whether your sample is normally distributed or not"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) The dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars = pd.read_csv(\"https://wagon-public-datasets.s3.amazonaws.com/Machine%20Learning%20Datasets/ML_cars_dataset_26_columns.csv\")\n",
    "cars.drop(columns = ['car_ID'], inplace = True)\n",
    "cars.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1.1) Basic Info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì How many cars do we have ‚ùì"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Inspect the types of your columns ‚ùì"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1.2) Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1.2.1) Anomalies in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì If you carefully look at the columns with *object*, which columns could/should be converted to numerical columns  ‚ùì \n",
    "\n",
    "üëâ Convert them.\n",
    "\n",
    "<details>\n",
    "    <summary><i>Hint</i></summary>\n",
    "\n",
    "* The _cylindernumber_ clearly needs to be converted to a numerical feature\n",
    "* As for the _doornumber_, it is up to you but we think that we can keep it as a categorical feature since most of the cars have either two or four doors, not one, three or five!\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1.2.2) Removing duplicates "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì How many duplicated rows do we have in this dataset (if so, get rid of any duplicated row) ‚ùì"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (1.2.3) Handling Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì How many NaN do we have ‚ùì"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary><i>Answer</i></summary>\n",
    "\n",
    "* No NaN here, it's a miracle üòá \n",
    "* If you have more than 30% of missing values in a row/column, drop the row/column üöÆ\n",
    "* Otherwise, you could use a *SimpleImputer* or a *KNN Imputer* to impute these missing values üòâ\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1.3) Having a glance at your target (`cars' price`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì How does your target look like in terms of _Distribution_, _Outliers_, _Gaussianity_  ‚ùì\n",
    "\n",
    "<details>\n",
    "    <summary><i>Code answer</i></summary>\n",
    "\n",
    "Save this block of code for future use ;)\n",
    "```python\n",
    "variable = 'price'\n",
    "y = cars[f\"{variable}\"]\n",
    "\n",
    "fig, ax = plt.subplots(1,3,figsize=(15,5))\n",
    "\n",
    "ax[0].set_title(f\"Distribution of the {variable}\")\n",
    "sns.histplot(data = cars, x = f\"{variable}\", kde=True, ax = ax[0])\n",
    "\n",
    "ax[1].set_title(f\"Boxplot of the {variable}\")\n",
    "sns.boxplot(data = cars, x = f\"{variable}\", ax=ax[1])\n",
    "\n",
    "ax[2].set_title(f\"Gaussianity of:the {variable}\")\n",
    "qqplot(cars[f\"{variable}\"],line='s',ax=ax[2]);    \n",
    "```\n",
    "    \n",
    "- The histogram with the estimated density shows us that ***the distribution of the prices is quite skewed and non-Gaussian***\n",
    "- The boxplot indicates some potential outliers. You should check the values, and see, that these are just more expensive cars. But none of the values seems to be completely out of range, like a false measurement et cetera...! #BusinessKnowledge \n",
    "- The QQ-plot is another proof that the distribution of the prices is not Gaussian:\n",
    "    - Remember that the scatter dots of your signal should match the $ y = x $ (45-degree line) closely, if the signal is Gaussian distributed.\n",
    "\n",
    "</details>       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) Preprocessing the features with a Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üé¨ Great, you have an overview of how the cars are distributed. \n",
    "\n",
    "üî• It's time to build a _preprocessing pipeline_ that we will, in a humble way, call the _preprocessor_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>ü§î How to deal with the <i>CarName</i> to predict the price of a car ? </summary>\n",
    "    \n",
    "1. You could extract the `CarBrand` using *Regex* techniques\n",
    "2. As we haven't studied yet how to handle ***textual data*** (cf. ***Machine Learning > Natural Language Processing***), let's ignore the `CarName` to predict the price for the moment.\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cars.drop(columns = [\"price\", \"CarName\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PIPELINE AND COLUMNTRANSFORMER\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer, make_column_selector\n",
    "from sklearn import set_config; set_config(display=\"diagram\")  \n",
    "\n",
    "# IMPUTERS\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# SCALERS\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler, MinMaxScaler\n",
    "\n",
    "# ENCODER\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2.1) Numerical Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Store the numerical features in a `X_num` variable ‚ùì"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Create a `num_transformer` pipeline to deal with numerical features ‚ùì\n",
    "<details>\n",
    "    <summary>üìö <i>Reminder about scalers</i></summary>\n",
    "    \n",
    "üëâ Great article <a href=\"https://towardsdatascience.com/scale-standardize-or-normalize-with-scikit-learn-6ccc7d176a02\">Scale, Standardize or Normalize with Scikit-Learn</a> written by Jeff Hale    \n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "source": [
    "> YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### (2.2) Categorical Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Store the categorical features in a variable called `cars_cat` ‚ùì"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Check how many columns you would end up with, if you decide to One Hot Encode them all. Is it a reasonable number ‚ùì\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Create a `cat_transformer` pipeline to deal with categorical features ‚ùì"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### (2.3) Full Preprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Create the `preprocessor` which combines the `num_transformer` and the `cat_transformer`  ‚ùì"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (3) Full pipeline with a Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üöÄ We can now try different regression model pipelined with the preprocessor üöÄ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Create a function that will create a Pipeline with the `preprocessor` and a regression model ‚ùì"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Testing different pipelined regression models ‚ùì\n",
    "\n",
    "\n",
    "ü§ì Do not forget to refer to [Scikit-Learn - Choosing the right estimator](https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Evaluating the pipelined models: which pipelined regressor performed the best ‚ùì"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üèÅ Congratulations!\n",
    "\n",
    "üíæ Don't forget to git add/commit/push your notebook...\n",
    "\n",
    "üöÄ You are now a master at `Pipeline` and `ColumnTransformer` !"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
